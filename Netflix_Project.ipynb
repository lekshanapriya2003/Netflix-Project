{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Netflix Project\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name**            - Lekshana Priya R\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix is a popular streaming service that provides its subscribers with a wide range of movies, TV shows, documentaries, and original content to watch on demand. The company was founded in 1997 as a DVD rental service but pivoted to an online streaming model in 2007. Since then, Netflix has grown into one of the most popular streaming services globally, with over 200 million subscribers in more than 190 countries as of 2021.\n",
        "\n",
        "Netflix's success is due in part to its innovative business model and emphasis on creating original content. The company invests heavily in producing its own movies and TV shows, which have won numerous awards and attracted high-profile talent. Netflix also uses sophisticated algorithms to recommend content to its users, based on their viewing history and preferences.\n",
        "\n",
        "\n",
        "This project aimed to identify patterns in the content available on the platform and group them into clusters based on similarities in their genres, sub-genres, release year, and other features. The project utilized machine learning algorithms such as K-means clustering and Hierarchical Clustering to cluster the data effectively."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Netflix Content Dataset (2019)\n",
        "Dataset Overview:**\n",
        "This dataset contains information about TV shows and movies available on Netflix as of 2019. The data was collected from Flixable, a third-party Netflix search engine.\n",
        "\n",
        "\n",
        "**Content Growth Trends:**\n",
        "\n",
        "The number of TV shows on Netflix has nearly tripled since 2010.\n",
        "\n",
        "The number of movies has decreased by more than 2000 titles over the same period.\n",
        "\n",
        "**Content Distribution:**\n",
        "\n",
        "This dataset provides insights into the types of content available in different countries.\n",
        "\n",
        "It reveals shifts in Netflix's content strategy, including a growing focus on TV shows over movies.\n",
        "\n",
        "**Project Goals:**\n",
        "In this project, the primary objectives are to:\n",
        "\n",
        "**Perform Exploratory Data Analysis (EDA):**\n",
        "\n",
        "Understand the distribution, popularity, and trends in the Netflix content library.\n",
        "\n",
        "Identify key factors influencing content availability.\n",
        "\n",
        "**Analyze Regional Content Availability:**\n",
        "\n",
        "Explore the variety of content offered in different countries.\n",
        "\n",
        "Identify regional content preferences and trends.\n",
        "\n",
        "**Evaluate Content Focus:**\n",
        "Assess whether Netflix has increasingly focused on TV shows rather than movies in recent years.\n",
        "\n",
        "**Content Clustering:**\n",
        "\n",
        "Cluster similar content by matching text-based features to identify potential content categories."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "from  sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.cluster import KMeans, SpectralClustering, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading the dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Replace 'your_file.csv' with the actual filename\n",
        "data = pd.read_csv('NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')"
      ],
      "metadata": {
        "id": "bDV8-SxEI-iI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "data.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(data[data.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total null values presnt in the data\n",
        "data.isnull().sum().sum()\n"
      ],
      "metadata": {
        "id": "IJ2g_2UFJQD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "msno.matrix(data, figsize = (15,8), fontsize =(12))"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding  Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "data.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# description of all the features.\n",
        "data.describe(include = 'all').T"
      ],
      "metadata": {
        "id": "PEOaAVW-kEXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "show_id :- Unique id for every movies/Tv shows\n",
        "\n",
        "type :- Identifier - A movie or Tv show\n",
        "\n",
        "title :- Title of the movie/show\n",
        "\n",
        "director :- Director of the show\n",
        "\n",
        "cast :- Actors involved in the show\n",
        "\n",
        "Country :- Country of production\n",
        "\n",
        "date_added :- Date is what added on netflix\n",
        "\n",
        "release_year :- Actual release year of the show\n",
        "\n",
        "rating :- TV rating of the show\n",
        "\n",
        "duration :- Total duration in minutes or number of seasons.\n",
        "\n",
        "listed_in :- Genre\n",
        "\n",
        "Description :- The summary descriptionAnswer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "variables_data = data.columns.to_list()\n",
        "for item in variables_data:\n",
        "  print('The Unique Values of', item, 'are:', data[item].unique())"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy of the data.\n",
        "df = data.copy()"
      ],
      "metadata": {
        "id": "CP9k0kInJhMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# handling null values.\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "6KY1IXywJjHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling the null values of director and cast.\n",
        "df.fillna({'director':'name absent', 'cast':'name missing'}, inplace = True)\n",
        "\n",
        "# filling the null values of rating and country with their mode.\n",
        "df['country'].fillna(df ['country'].mode()[0], inplace = True)\n",
        "df['rating'].fillna(df ['rating'].mode()[0], inplace = True)\n",
        "\n",
        "# droping the observation with null values present in date added.\n",
        "df = df[df['date_added'].notna()]"
      ],
      "metadata": {
        "id": "6s2ioWZ8Jlh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the null value counts again.\n",
        "df.isnull().sum().sum()"
      ],
      "metadata": {
        "id": "r4ykcWTuJpEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the data type of data.\n",
        "df.date_added.dtype"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove leading/trailing whitespace first\n",
        "df['date_added'] = df['date_added'].str.strip()\n",
        "\n",
        "# Convert to datetime, allowing mixed formats\n",
        "df['date_added'] = pd.to_datetime(df['date_added'], format='mixed', errors='coerce')\n",
        "\n",
        "# Extract day, month, year\n",
        "df['added_day'] = df['date_added'].dt.day\n",
        "df['added_month'] = df['date_added'].dt.month\n",
        "df['added_year'] = df['date_added'].dt.year"
      ],
      "metadata": {
        "id": "LHAVxk0gJtF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "_wFH1EM0Ju3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rating value counts.\n",
        "df['rating'].value_counts()"
      ],
      "metadata": {
        "id": "O19QMIBPJ4Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting rating into understandable format.\n",
        "\n",
        "rename_rating = {\n",
        "    'TV-PG': 'Older Kids',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Kids',\n",
        "    'TV-Y7': 'Kids',\n",
        "    'TV-14': 'Teens',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teens',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Older Kids',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "\n",
        "df['rating'] =df['rating'].replace(to_replace = rename_rating)\n",
        "df['rating'].unique()"
      ],
      "metadata": {
        "id": "gNAU3UVJJ_KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set a custom color palette\n",
        "sns.set_palette([\"#FF6F61\", \"#5D9CEC\"])\n",
        "\n",
        "# Plot the type counts\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.countplot(x='type', data=df)\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(\"Distribution of Content Types on Netflix\", fontsize=16, fontweight='bold')\n",
        "plt.xlabel(\"Content Type\", fontsize=14)\n",
        "plt.ylabel(\"Count\", fontsize=14)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SdbSTS4hKO0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose this chart to visualize the distribution of content types on Netflix because it provides a clear overview of the relative proportions of Movies and TV Shows in the platform's catalog. By using a custom color palette, the chart highlights the difference between these two categories, making the insights more visually engaging. This distribution is important for understanding Netflix's content strategy, including its increasing focus on original TV Shows in recent years. Additionally, this straightforward representation makes it easy to identify shifts in content preferences and trends."
      ],
      "metadata": {
        "id": "W-5To2ZTk0bk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Top ten countries based on total production.**"
      ],
      "metadata": {
        "id": "4Y2mRP70L8oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count values and convert to DataFrame\n",
        "top_countries = df['country'].value_counts().head(10).reset_index()\n",
        "top_countries.columns = ['Country Name', 'Total number of production']  # Rename properly\n",
        "\n",
        "# Plot with custom colors\n",
        "plt.figure(figsize=(15, 7))\n",
        "sns.barplot(data=top_countries, x='Country Name', y='Total number of production', palette=[\"#5DADE2\", \"#F39C12\", \"#58D68D\", \"#AF7AC5\", \"#EC7063\", \"#F4D03F\", \"#48C9B0\", \"#AAB7B8\", \"#D68910\", \"#C0392B\"])\n",
        "plt.title('Top 10 Countries by TV Shows and Movies Production', fontsize=18, fontweight='bold')\n",
        "plt.xlabel('Country', fontsize=14)\n",
        "plt.ylabel('Total Productions', fontsize=14)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This bar chart visualizes the Top 10 Countries by TV Shows and Movies Production on Netflix. The customized color palette was chosen to differentiate each country distinctly, highlighting the diverse content contributions from various regions. The chart effectively captures the global reach of Netflix's content library, emphasizing the dominant production hubs like the United States, India, and United Kingdom. This visualization provides valuable insights into the geographic distribution of Netflix's content, reflecting the company's strategy to expand its global footprint and cater to regional audiences.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GKpnb_2NMMW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Totlal number of contents wrt added_year, added_month, added_day, release_year, rating, type.**"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Variables to visualize\n",
        "var = ['added_year', 'added_month', 'added_day', 'release_year', 'rating', 'type']\n",
        "\n",
        "# Custom color palette\n",
        "custom_palette = sns.color_palette([\"#FF6F61\", \"#5D9CEC\", \"#48C9B0\", \"#F4D03F\", \"#AF7AC5\", \"#EC7063\"])\n",
        "\n",
        "# Plot each variable with the custom color palette\n",
        "for i, col in enumerate(var):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(x=col, data=df, palette=[custom_palette[i % len(custom_palette)]])\n",
        "    plt.title(f'Distribution of {col.capitalize()}', fontsize=18, fontweight='bold')\n",
        "    plt.xlabel(col.capitalize(), fontsize=14)\n",
        "    plt.ylabel('Count', fontsize=14)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Year of Addition:\n",
        "\n",
        "The majority of Netflix's content was added between 2018 and 2020, with 2019 marking the peak year for content additions.\n",
        "\n",
        "The drop in 2021 can be attributed to the global COVID-19 pandemic, which disrupted production pipelines worldwide.\n",
        "\n",
        "Month of Addition:\n",
        "\n",
        "December stands out as the most active month for content additions, likely due to the holiday season when viewership typically spikes.\n",
        "\n",
        "Other high-activity months include October, November, and January, aligning with major holiday seasons and year-end promotions.\n",
        "\n",
        "Day of Addition:\n",
        "\n",
        "Content is most frequently added on the 1st and 15th of each month, possibly reflecting standard content update cycles and contractual release schedules.\n",
        "\n",
        "Year of Release:\n",
        "\n",
        "The volume of content released each year saw a steady rise until 2021, where it faced a notable decline, again likely due to pandemic-related restrictions and production delays.\n",
        "\n",
        "Content Ratings:\n",
        "\n",
        "The majority of Netflix's catalog is adult-oriented, with fewer titles targeted at kids or family audiences, reflecting its focus on mainstream and mature content.\n",
        "\n",
        "Content Type:\n",
        "\n",
        "Movies dominate Netflix's library, with approximately 5000 titles, while TV shows account for around 2500 titles, highlighting the platform's emphasis on long-form storytelling.\n",
        "\n"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Directors**"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# count of unique director\n",
        "df['director'].nunique()"
      ],
      "metadata": {
        "id": "pDVPhczeMrmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top directors.\n",
        "df['director'].value_counts()"
      ],
      "metadata": {
        "id": "46bok0pgMtbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(y=df['director'], data = df, order = df['director'].value_counts().index[1:15])"
      ],
      "metadata": {
        "id": "1WTJmuSCMwsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ra√∫l Campos, Jan Suter, Marcus Raboy, Jay Karas, Cathy Garcia-Molina, etc are the top directors. It would have been easier to get more insights if some of the values in the director column were not null."
      ],
      "metadata": {
        "id": "nnJX2DFUMzRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Titles**"
      ],
      "metadata": {
        "id": "p0L3yEmRM1nh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# most frequent words used in titles.\n",
        "#Importing wordcloud\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "#Most occurred word in title\n",
        "plt.subplots(figsize=(20,10))\n",
        "stopwords = set(STOPWORDS)\n",
        "text = \" \".join(df.title)\n",
        "wordcloud = WordCloud(stopwords=stopwords,background_color='white',width=1000,height=800).generate(text)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SeIIuD5EM5mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Christmas, love, world, story, life, girl, etc are the most frequent words used in the title of the contents."
      ],
      "metadata": {
        "id": "s8DY26OJM8sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Genres**"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# value counts.\n",
        "df['listed_in'].value_counts()"
      ],
      "metadata": {
        "id": "NvioZlz7NEWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization oftop ten genres.\n",
        "plt.figure(figsize = (12,8))\n",
        "sns.countplot(y=df['listed_in'], data=df, order = df['listed_in'].value_counts().index[:10])"
      ],
      "metadata": {
        "id": "GjdpOG8GNIxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  **Genres**"
      ],
      "metadata": {
        "id": "3s67lO2CNNhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# seprating the genres from every content and assigning them to a new genres list.\n",
        "genres = df['listed_in']\n",
        "genre_list=[]\n",
        "for i in genres:\n",
        "  i=i.split(\",\")\n",
        "  for j in i:\n",
        "    genre_list.append(j)"
      ],
      "metadata": {
        "id": "OdZlOy97NRal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting genre list into dataframe.\n",
        "gen_df = pd.DataFrame(genre_list)\n",
        "gen_df.rename(columns={0:'genres'}, inplace = True)\n",
        "gen_df.value_counts().head(15)"
      ],
      "metadata": {
        "id": "rW3UGBCsNTQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of top 15 genres on netflix.\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(y=gen_df['genres'], data=gen_df, order = gen_df['genres'].value_counts().index[:15])"
      ],
      "metadata": {
        "id": "g9Zzco-kNWqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in the above-count plot, international movies, dramas, comedies, and action & adventure are some of the top genres."
      ],
      "metadata": {
        "id": "BlwjvIhaNY7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Cast**"
      ],
      "metadata": {
        "id": "6hmC5URXNakR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting top crew members from cast.\n",
        "crew_list=[]\n",
        "for i in df['cast']:\n",
        "  i=i.split(',')\n",
        "  for j in i:\n",
        "    crew_list.append(j)"
      ],
      "metadata": {
        "id": "mrAZ-kzKNcGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting the list into dataframe\n",
        "crew_df = pd.DataFrame(crew_list)\n",
        "crew_df.rename(columns = {0:'actr_actrs'}, inplace = True)\n",
        "crew_df"
      ],
      "metadata": {
        "id": "6NglE8dmNdzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 15 actor or actress on netflix.\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(y= crew_df['actr_actrs'], data = crew_df, order = crew_df['actr_actrs'].value_counts().index[1:15])"
      ],
      "metadata": {
        "id": "e-45HF0aNgvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anupam Kher, Takahiro Sakurai, Shah Rukh Khan, Boman Irani, etc are some of the top actors on Netflix. I had also some null values present in the cast column. It would have been easier to get more insights if some of the values in the cast column were not null."
      ],
      "metadata": {
        "id": "gj8VFQbBNkac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Movies Duration**"
      ],
      "metadata": {
        "id": "TY9jan5NNmIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separating the movies data from type column.\n",
        "movie_df = df[df['type']=='Movie']['duration'].apply(lambda x: x.split(\" \")[0]).reset_index()\n",
        "movie_df"
      ],
      "metadata": {
        "id": "rJSU6k1HNuNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of movies duration distribution.\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.distplot(movie_df['duration'], color = 'red')"
      ],
      "metadata": {
        "id": "7IvEzjvfNwqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The range duration of the movies on Netflix is between 50 to 150 minutes. There are also some movies of 300 minutes."
      ],
      "metadata": {
        "id": "-cK1mwdCN4qL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TV Shows Duration**"
      ],
      "metadata": {
        "id": "zb-HoIghN6Ve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tv show df.\n",
        "tv_df = df[df['type']=='TV Show']\n",
        "tv_df['duration'].value_counts()\n",
        "# df.loc[df['type']=='TV Show']['duration'].value_counts()"
      ],
      "metadata": {
        "id": "7gv1A1NKN28e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization of tv show duration.\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.countplot(y = tv_df['duration'])"
      ],
      "metadata": {
        "id": "9nIICoNfN250"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most TV Shows has only 1 or 2 seasons. There are only few TV Shows with more than 2 seasons."
      ],
      "metadata": {
        "id": "v6FtnRbROBtD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "counts wrt type of the content"
      ],
      "metadata": {
        "id": "2e0-gsKSODhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Variables to visualize\n",
        "var = ['added_year', 'added_month', 'added_day', 'release_year', 'rating', 'type']\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(18, 30))\n",
        "\n",
        "# Custom color palette for content types\n",
        "custom_palette = [\"#5DADE2\", \"#EC7063\"]\n",
        "\n",
        "# Plot each variable with the custom color palette\n",
        "for idx, col in enumerate(var):\n",
        "    plt.subplot(4, 2, idx + 1)\n",
        "    sns.countplot(x=col, hue='type', data=df, palette=custom_palette)\n",
        "    plt.title(f'Distribution of {col.capitalize()} by Content Type', fontsize=18, fontweight='bold')\n",
        "    plt.xlabel(col.capitalize(), fontsize=14)\n",
        "    plt.ylabel('Count', fontsize=14)\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "# Adjust layout to avoid overlap\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "wgGzBz7EN23a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights Found.\n",
        "Netflix has been increasingly focusing on TV Shows rather than movies in recent years.\n",
        "Most of the content on Netflix are added in the month of December and January. In Which movies are added the most.\n",
        "Maximum contents are added on the first day of the month.\n",
        "Adding the number of content on Netflix is increased in recent years.\n",
        "Most of the movies and tv shows are for adults. Very few contents are for kids."
      ],
      "metadata": {
        "id": "sgV-ch_iOKnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Type content available in different countries.**"
      ],
      "metadata": {
        "id": "CFffBKgGmbJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# total production of country wrt type of the content.\n",
        "plt.figure(figsize=(15,8))\n",
        "sns.countplot(x = df['country'], hue='type', data = df, order = df['country'].value_counts().index[:15])"
      ],
      "metadata": {
        "id": "pr-in5KjN20Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "US has the most number of movies and tv shows type content. While India comes in second place for movies on Netflix. But UK comes in second place in terms of tv shows. Followed by South Korea and Canada. Other countries have a very less number of contents added on Netflix."
      ],
      "metadata": {
        "id": "ow8WXeReOQQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Engineering**"
      ],
      "metadata": {
        "id": "SjLJhO9HOSEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no outliers in the data so I don't have to handle any outliers here. While I cleaned the data completely in the data wrangling section. Like handled the null values, converted the ratings into an understandable format, and extracted the date data from date_added column."
      ],
      "metadata": {
        "id": "Fo89c0LIOUsp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Textual Data Preprocessing**"
      ],
      "metadata": {
        "id": "ZoJ6hwLNOWZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "cVXzCVBaN2xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combinig the textual data to proceed with NLP\n",
        "df['text'] = df['cast']+df['listed_in']+df['rating']+df['description']+df['director']+df['rating']+df['country']\n",
        "df['text'][0]"
      ],
      "metadata": {
        "id": "WLrEXOMiOalX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to remove punctuation and stopwords.**"
      ],
      "metadata": {
        "id": "S8pwC8OPOcg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "    import string\n",
        "    # replacing the punctuations with no space,\n",
        "    # which in effect deletes the punctuation marks\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "eTITxEG4N2uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying function to remove punctuation.\n",
        "df['text']=df['text'].apply(remove_punctuation)\n",
        "df['text'][0]"
      ],
      "metadata": {
        "id": "WO4DI0y_N2rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing stopwords**"
      ],
      "metadata": {
        "id": "nx2k-0JdOjwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "en9jB1YqOjig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading stop words.\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "E7rcwDbVOmV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assigning the stopwords to a variable\n",
        "import numpy as np\n",
        "stop_words = stopwords.words('english')\n",
        "\n",
        "# displaying stopwords\n",
        "np.array(stop_words)"
      ],
      "metadata": {
        "id": "-Z0paJbhOojS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove stopwords from a given text\n",
        "def remove_stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "SXjULmJBOof5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying the function on text data.\n",
        "df['text'] = df['text'].apply(remove_stopwords)\n",
        "df['text'][0]"
      ],
      "metadata": {
        "id": "7lE8smVbOod0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stemming operations**"
      ],
      "metadata": {
        "id": "nkjc5UG_Ox9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Normalization"
      ],
      "metadata": {
        "id": "EGusju5_Oxtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function for stemming and lemmatization.\n",
        "from nltk.stem import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def stemming(text):\n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)"
      ],
      "metadata": {
        "id": "e5S-L4EYOxW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# applying the function on text data.\n",
        "df['text'] = df['text'].apply(stemming)\n",
        "df['text'][0]"
      ],
      "metadata": {
        "id": "TylEJ6w2Ooaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# tfidf object initialization\n",
        "tfidf = TfidfVectorizer(stop_words='english', lowercase=False, max_features=10000)  # max features = 10000 to prevent system from crashing\n",
        "\n",
        "# fitting the vectorizer using the text data\n",
        "tfidf.fit(df['text'])\n",
        "\n",
        "# collecting the vocabulary items used in the vectorizer\n",
        "dictionary = tfidf.vocabulary_.items()"
      ],
      "metadata": {
        "id": "TS8dIZuqO6OA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting vector into array form for clustering\n",
        "X = tfidf.transform(df['text']).toarray()\n",
        "\n",
        "# summarize encoded vector\n",
        "print(X)\n",
        "print(f'shape of the vector : {X.shape}')\n",
        "print(f'datatype : {type(X)}')"
      ],
      "metadata": {
        "id": "hZQdAruVOoYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying PCA to reduce dimension**"
      ],
      "metadata": {
        "id": "aYrIY-iYO-Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Assuming X is your feature matrix (e.g., after vectorization)\n",
        "# If X is very large, use a smaller sample:\n",
        "X_sampled = X[:1000]  # Use the first 1000 samples for faster testing\n",
        "\n",
        "# Standardizing the data (PCA is affected by scale)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_sampled)\n",
        "\n",
        "# Applying PCA\n",
        "pca = PCA(n_components=2, random_state=42)  # Reduce to 2 components for simplicity\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Check the explained variance ratio\n",
        "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")"
      ],
      "metadata": {
        "id": "UEXJAcnjOoVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the explained variance ratio for each component\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Plot the explained variance ratio\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(np.cumsum(explained_variance_ratio))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.title('Explained Variance Ratio vs Number of Components')\n",
        "plt.axhline(y= 0.9, color='red', linestyle='--')\n",
        "plt.axvline(x= 4000, color='green', linestyle='--')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Svii9TxlOoT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As I can see clearly in the above graph that the data with 4000 components cover 90 percent variation. If we have approximately 7000 components then it will capture 100% variance but that will increase the model complexity. So with this information, i'm going to reduce the dimension."
      ],
      "metadata": {
        "id": "ZmN-MVEDPFDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "PaAQ0OdOOoRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Use TruncatedSVD for sparse data\n",
        "svd = TruncatedSVD(n_components=400, random_state=42)  # Try 400 instead of 4000 for faster results\n",
        "X_reduced = svd.fit_transform(X)\n",
        "\n",
        "print(\"New shape:\", X_reduced.shape)"
      ],
      "metadata": {
        "id": "jxfELfyaOoO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Dimensionality reduction for sparse TF-IDF data\n",
        "svd = TruncatedSVD(n_components=400, random_state=42)\n",
        "X_reduced = svd.fit_transform(X)\n",
        "\n",
        "# Now safe to copy\n",
        "net_data = X_reduced.copy()"
      ],
      "metadata": {
        "id": "IkYvLKCpboZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model**"
      ],
      "metadata": {
        "id": "AIx9V1gwPYOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Means Clustering**"
      ],
      "metadata": {
        "id": "wVr9zuBGPYCy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Elbow Method**"
      ],
      "metadata": {
        "id": "a_N7iDVgPfMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the k value through elbow method.\n",
        "k_value = range(2,12)\n",
        "ssd_value = []\n",
        "for k in k_value:\n",
        "  kmeans = KMeans(n_clusters=k, init = 'k-means++', random_state = 42)\n",
        "  kmeans.fit(net_data)\n",
        "  ssd_value.append(kmeans.inertia_)"
      ],
      "metadata": {
        "id": "lUEfslclOoJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting the elbow curve.\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(k_value, ssd_value, 'bx-')\n",
        "plt.xlabel('Values of K')\n",
        "plt.ylabel('Sum of squared distance')\n",
        "plt.title('Elbow Method')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gKTDnjqgPiTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here i can see a sudden stipness after 6 clusters. After 6 cluster value, the within-cluster sum of squares (WSS) starts to decrease at a slower rate. So according to elbow curve the optimal value for k is 6. Let's see the silhoutte score."
      ],
      "metadata": {
        "id": "U4S7FbGPeWkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Silhoutte Score**"
      ],
      "metadata": {
        "id": "EXdn1OzveeND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# range for k values.\n",
        "n_cluster_range = range(2,12)\n",
        "\n",
        "# empty list to store silhouette score and cluster lables\n",
        "silhouette_avg_score = []\n",
        "cluster_label_list = []\n",
        "\n",
        "# running a loop to find the score with optimal k value.\n",
        "for k in n_cluster_range:\n",
        "\n",
        "  # initializing the instance\n",
        "  kmeans = KMeans()\n",
        "\n",
        "  # predicting the cluster lables\n",
        "  cluster_labels = kmeans.fit_predict(net_data)\n",
        "\n",
        "  # cluster centres.\n",
        "  centroids = kmeans.cluster_centers_\n",
        "\n",
        "  # storing the cluster lables in cluster lable list\n",
        "  cluster_label_list.append(cluster_labels)\n",
        "\n",
        "  # finding silhouette score and storing them into silhouette average score list.\n",
        "  silhouette_avg = silhouette_score(net_data, cluster_labels)\n",
        "  silhouette_avg_score.append(silhouette_avg)\n",
        "\n",
        "  # Plotting the data points with cluster labels\n",
        "  plt.figure(figsize = (12,6))\n",
        "  plt.scatter(net_data[:, 0], net_data[:, 1], c=cluster_labels)\n",
        "  plt.title(f'Data Points with {k} Clusters')\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "G_GQBkb3eWKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see here the data points with 6 clusters are good enough. It would be more clear with silhouette score visualization."
      ],
      "metadata": {
        "id": "59bHEK4qfIKj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization of silhouette score with different value of k."
      ],
      "metadata": {
        "id": "TrXxiMkufKWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the silhouette scores as a function of number of clusters\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(n_cluster_range, silhouette_avg_score, marker='o')\n",
        "\n",
        "# Add labels to the plot\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Scores for Different Number of Clusters')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8XlqrXWjOoGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the above line plot, with 6 clusters we get a good score. Which is really good as compared to different number of clusters.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LB93KP62fRYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final KMeans model.**"
      ],
      "metadata": {
        "id": "Bc_UrPWFfXvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# final model.\n",
        "kmeans= KMeans(n_clusters=6, max_iter=10000, tol = 1e-4, n_init = 1, random_state= 42)\n",
        "kmeans.fit(net_data)\n",
        "label = kmeans.fit_predict(net_data)"
      ],
      "metadata": {
        "id": "FMzRHpufOn-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model evaluation.\n",
        "score = silhouette_score(net_data, label)\n",
        "print(\"Silhouette score is {}\".format(score))"
      ],
      "metadata": {
        "id": "5zbxOagSOnwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new column as cluster with cluster number5s.\n",
        "df['cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "W4fMpSzTfgQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first five rows.\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3g3pgxDhfiKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# value count of different clusters.\n",
        "df['cluster'].value_counts()"
      ],
      "metadata": {
        "id": "dmAdOYOefkIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Size of clusters formed\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.countplot(x =df['cluster'], data = df)"
      ],
      "metadata": {
        "id": "0vKzOs5Tfl3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cluster 5 and 0 has got the maximum number of data points while cluster 1 and 3 has got less than 1000 data points. Cluster 2 has approximately 1200 data points."
      ],
      "metadata": {
        "id": "q6hJdzccfn16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting for cluster in each type\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x=df['type'],palette=\"BuPu\",hue=df['cluster'])\n",
        "plt.title(\"cluster in each type\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pwFU_YEcfpNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maximum content in all the cluster labels are movies."
      ],
      "metadata": {
        "id": "KZEPzDlbfrur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dendogram\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QoxjYSJkftkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using the dendogram to find the optimal number of clusters\n",
        "import scipy.cluster.hierarchy as sch\n",
        "plt.figure(figsize=(13,8))\n",
        "dendrogram = sch.dendrogram(sch.linkage(net_data, method = 'ward'))\n",
        "plt.title('Dendrogram')\n",
        "plt.xlabel('Content')\n",
        "plt.ylabel('Euclidean Distances')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "55pO14-lfzkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per the dendrogram if we cut the tallest vertical line which shows the distance between those clusters, we'll get 4 clusters with 5 euclidean distance."
      ],
      "metadata": {
        "id": "HSqilgdTf2K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hierarchical Clustering**"
      ],
      "metadata": {
        "id": "2YzHGaRHf4XB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agglomerative Clustering**"
      ],
      "metadata": {
        "id": "KLlCsFJVf7Ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Fitting hierarchical clustering\n",
        "hc = AgglomerativeClustering(n_clusters=4, metric='euclidean', linkage='ward')\n",
        "y_hc = hc.fit_predict(net_data)"
      ],
      "metadata": {
        "id": "BNtQW4A2gxzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the clusters (two dimensions only)\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.scatter(net_data[y_hc == 0, 0], net_data[y_hc == 0, 1], s = 100, c = 'red', label = 'Cluster 1')\n",
        "plt.scatter(net_data[y_hc == 1, 0], net_data[y_hc == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')\n",
        "plt.scatter(net_data[y_hc == 2, 0], net_data[y_hc == 2, 1], s = 100, c = 'green', label = 'Cluster 3')\n",
        "plt.scatter(net_data[y_hc == 3, 0], net_data[y_hc == 3, 1], s = 100, c = 'magenta', label = 'Cluster 4')\n",
        "#plt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 100, c = 'green', label = 'Target')\n",
        "\n",
        "plt.title('Clusters of Contents')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jAlqsNIkhOPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "Qgm7egzhm3Ca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project provided a comprehensive analysis of Netflix's content library, revealing key trends and patterns in content addition, release, and types. The majority of Netflix's content was added between 2018 and 2020, with a peak in 2019, coinciding with the platform's growing popularity. However, content additions dropped significantly in 2021, likely due to the disruptions caused by the COVID-19 pandemic. Seasonal trends were also evident, with the highest number of content releases occurring in December, likely due to the holiday season.\n",
        "\n",
        "\n",
        " The analysis showed that Netflix's content release volume increased steadily until 2021, after which it declined, reflecting the industry's response to the global pandemic. In terms of content types, Netflix‚Äôs catalog is predominantly adult-oriented, with movies outnumbering TV shows. This reflects the platform's focus on catering to a broad, global audience with diverse content formats.\n",
        "\n",
        "\n",
        "  Additionally, the analysis highlighted the top-producing countries, demonstrating Netflix's global reach and investment in international markets. Overall, these insights into Netflix's content strategy underscore how the platform has adapted to evolving market conditions and the changing dynamics of global production."
      ],
      "metadata": {
        "id": "8JO5x5dcm5nO"
      }
    }
  ]
}